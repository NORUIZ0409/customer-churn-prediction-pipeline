# ğŸ”® E-commerce Customer Churn Prediction

An end-to-end machine learning project to **predict customer churn** for a subscription-based e-commerce service.  
This repository contains a full pipeline from data ingestion and cleaning to model training, evaluation, and deployment via a multi-page, interactive web application.

---

## ğŸ¬ Demo
Below is a demonstration of the final **Streamlit web application**, which uses the best-trained model to make live predictions.

> *(A GIF of your `app.py` running would be perfect here. You can use a tool like [ScreenToGIF](https://www.screentogif.com/) or [LICEcap](https://www.cockos.com/licecap/) to record your screen.)*

---

## ğŸ“‹ Table of Contents
- [Project Overview](#-project-overview)
- [Features](#-features)
- [Tech Stack & Libraries](#-tech-stack--libraries)
- [Project Structure](#-project-structure)
- [Setup and Installation](#-setup-and-installation)
- [How to Run](#-how-to-run)
- [Results & Evaluation](#-results--evaluation)
- [License](#-license)

---

## ğŸ“ Project Overview
The primary goal of this project is to proactively identify customers who are at a high risk of **churning** (canceling their subscription).  
By leveraging customer data, we build a **classification model** that provides a **probability of churn for each customer**.  

This allows the business to take targeted actions, such as offering discounts or support, to retain valuable customers.

The project is built as a **modular pipeline**, ensuring that each step of the machine learning lifecycle is separated and maintainable. It uses **MLflow** for robust experiment tracking and a comprehensive **Streamlit suite** to provide a user-friendly interface for non-technical users to interact with the final model and explore the data.

---

## âœ¨ Features
- **End-to-End Modular Pipeline**: Distinct, reusable scripts for each stage (data_ingestion, feature_engineering, model_training, etc.).
- **Data Cleaning & Preprocessing**: Handles missing values, data type conversions, and prepares the data for modeling.
- **Advanced Feature Engineering**: Creates new, insightful features (e.g., tenure groups, service counts).
- **Multi-Model Training**: Trains and compares Logistic Regression, Random Forest, and XGBoost to find the best performer.
- **Experiment Tracking with MLflow**: Logs parameters, metrics, models, and artifacts for every run.
- **Model Evaluation**: Generates performance reports including confusion matrix and ROC curve.
- **Multi-Page Interactive Web UI** (Streamlit):
  - ğŸ“ˆ Real-time prediction dashboard  
  - ğŸ“‚ Batch prediction for CSV files  
  - ğŸ”¬ Model performance analysis  
  - ğŸ“Š Interactive data explorer  

---

## ğŸ› ï¸ Tech Stack & Libraries
**Programming Language**: ğŸ Python 3.11+  

**Core Libraries**  
- Pandas â†’ Data manipulation & analysis  
- Scikit-learn â†’ Preprocessing, modeling, and evaluation  
- XGBoost â†’ Gradient boosting model  

**Experiment Tracking**  
- MLflow â†’ Logging experiments, parameters, metrics, and models  

**Web Application & Visualization**  
- Streamlit â†’ Interactive user interface  
- Plotly & Plotly Express â†’ Dynamic, interactive charts  

**Utilities**  
- PyYAML â†’ Configuration management  

---

## ğŸ“‚ Project Structure
```bash
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml                 # Configuration file for paths, parameters, etc.
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ ecommerce_churn_data.csv  # Raw dataset
â”‚   â””â”€â”€ processed/                    # Cleaned & processed data (train/test sets)
â”œâ”€â”€ reports/                          # Evaluation artifacts like plots
â”œâ”€â”€ saved_models/                     # Trained model and preprocessor files (.pkl)
â”œâ”€â”€ src/                              # Source code for the pipeline
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_ingestion.py
â”‚   â”œâ”€â”€ feature_engineering.py
â”‚   â”œâ”€â”€ model_training.py
â”‚   â”œâ”€â”€ model_evaluation.py
â”‚   â”œâ”€â”€ pipeline.py                   # Run the entire training pipeline
â”‚   â””â”€â”€ utils.py                      # Utility functions
â”œâ”€â”€ app.py                            # Streamlit web application
â”œâ”€â”€ requirements.txt                  # Python dependencies
â””â”€â”€ README.md                         # Project documentation
